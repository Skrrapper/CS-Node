【数据结构】万字长文：排序算法汇总——十大排序+外排序（附源码+图解）

作为基础算法的中流砥柱部分，排序算法一直都是计算机学习者们不可忽略的一部分。而其中的算法思想也蕴含着许多在今后的算法学习甚至是整个计算机技术的学习之中仍然熠熠生辉的算法思想，它们引领着我们不断探索算法的奥秘之处。所以，学习排序算法是十分重要的。
本文将从十大内排序算法以及外排序的分类角度来进行详细解读，如有不解或者是疏漏还请多多见谅~一起讨论学习！

## 排序简介

在《算法导论》这本经典的算法学习中，我们可以看到“排序”二字的出现频率极高，更是直接拿出一整章节来对其中的快速排序、堆排序等进行讲解。

![image-20240819175224046](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240819175224046.png)

了解一种算法的重要程度，我们可以直接在这本书中所占的权重来粗略得知。

在维基百科中，对排序算法的解释是这样的。

![image-20240823091732806](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240823091732806.png)

**排序算法**（英语：Sorting algorithm）是一种将一组特定的数据按某种顺序进行排列的算法。简单来说，就是将一堆杂乱的数据处理成有序的数据。我们在进行排序的时候必须遵循两个原则：

- 输出的结果一般是递增或者是递减序列，这里的递增递减既可以代表着“有序”二字；
- 输出结果是原来输入的一种重新组合，不得删除或新增数据

在遵循这两个原则的基础上，诞生了众多不同的排序算法，它们或许在排序的过程中遵守着自己不同的规律，但是始终都遵守着以上两个原则。

排序算法同样也根据复杂度来区分其速度，同时也引入了一个新的判定概念——稳定性。

## 稳定性的概念

在排序过程中，我们会涉及到比较的概念，也就涉及到相对位置的概念，举例：

排序前，红5在蓝5的前面，蓝5在红5的后面；

![image-20240819180457838](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240819180457838.png)

在排序后，如果红5依旧蓝5前面，那么就是稳定的——**我们可以理解为两者的相对位置只要不变，就是稳定的**，如果变化了，**实际上就会打乱原有的顺序，在内存存储和某些问题上会产生变动，从而就不稳定了**

排序的稳定性不是决定这个算法是否好用的唯一标准，甚至可以说一个排序稳不稳定完全不影响它的速度和可用性。**但是从一个对象的多个属性上来说**，好的稳定性可以帮助在保持整体排序的同时能够实现不同属性的排序——**由此可见稳定性的意义是从需求上出发的。**各个排序算法的稳定性将在后续分别进行分析。

![image-20240817175329801](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240817175329801.png)

接下来将对各个排序算法进行逐帧分析。

------



## 插入排序

### 算法思想

插入排序的算法思想其实很容易理解，它秉持着一个不变的循环：比较->交换->比较->交换...因为我们排序最终的目的是要得到递增或者递减的数据，那么在原有的数据中，我们可以将数据依次两两进行比较：

- 如果是升序，那么就将较小的放在较大的前面
- 如果是降序，那么就将较大的放在较小的前面

### 图解

![插入排序](C:/Users/SKRRAP~1/AppData/Local/Temp/7zO4148E88D/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F.gif)

我们看图解中，单次比较过程中，拿出来比较的数只会同它左侧的数进行比较，而被比较的数随着比较结束也会根据具体情况向后移动或者是进行交换，向后移动的过程也称为——补位。在全程的比较中，随着补位和交换的进行，进行比较操作的数只会与曾经进行过比较操作的数进行比较——简单来说，就是比较与被比较是交替进行的。我们总结插入排序算法的核心思路——**将待排列元素划分为「已排序」和「未排序」两部分，每次从「未排序的」元素中选择一个插入到「已排序的」元素中的正确位置。**

### C语言代码分析

```c
//升序情况
void InsertSort(int* arr, int n)
{
	int end = n - 1;//从最后一个数据开始进行比较
	int tmp = arr[end];//保存最后一个数据
	while (end >= 0)
	{
		if (tmp <= arr[end])//当tmp小于等于arr[end]时，说明tmp还没有找到合适的位置
		{
			arr[end + 1] = arr[end];//那么就将arr[end]向后移动
			end--;//继续向前比较
		}
		else//当tmp大于arr[end]时，说明tmp已经找到了合适的位置
		{
			break;//那么就直接退出循环
		}
	}
	arr[end + 1] = tmp;
}

//降序情况
void InsertSort2(int* arr, int n)
{
	int begin = 0;//从第一个数据开始进行比较
	int tmp = arr[begin];//保存第一个数据
	while (begin <= n - 1)
	{
		if(tmp>=arr[begin])//当tmp大于等于arr[begin]时，说明tmp还没有找到合适的位置
		{
			arr[begin - 1] = arr[begin];//那么就将arr[begin]向后移动
			begin++;//继续向后比较
		}
		else//当tmp小于arr[begin]时，说明tmp已经找到了合适的位置
		{
			break;//那么就直接退出循环
		}
		arr[begin + 1] = tmp;
}
```

在现实生活中，扑克牌的排序事实上就是遵循着插入排序的思想：

![insertion sort animate example](https://oi-wiki.org/basic/images/insertion-sort-animate.svg)

### 时间复杂度

- 插入排序的最优时间复杂度为**O(n)**，在数列几乎有序时效率很高。

- 插入排序的最坏时间复杂度和平均时间复杂度都为**O(n^2^)**。

### 稳定性

鉴于插入排序不会改变前后元素的相对位置，所以： **稳定**



## 希尔排序

### 算法思想

**希尔排序（Shell Sort）**是一种**改进的插入排序算法**，希尔排序的创造者Donald Shell想出了这个极具创造力的改进。其时间复杂度取决于**步长序列（gap）**的选择。**我们在插入排序**中，会发现是对整体数据直接进行了统一的插入排序，每个数据之间的间隙是**1**，这里的**1**指的就是步长序列**gap**。在**希尔排序**中，我们会将整体数据一分为多份，进行散布式的插入排序，这时候每一个子序列之间的间隙就是**gap**——那么事实上我们也可以将插入排序就看成是**gap=1**的希尔排序。

我们来具体分析希尔排序的算法步骤：

- 将待排序序列分为若干个序列，每个序列的间距n（gap）需要相同
- 将这些子序列分别进行插入排序
- 不断减小这个间距

那么我们减小这个间距的目的是什么呢？

当**gap > 1**时我们可以称为**预排序**，目的是**让数组更接近于有序**。当**gap = 1**时，数组已经接近有序的了，就整体而言，最后一次整体的插入排序就可以大大提高效率——我们从插入排序的时间复杂度分析也可以看出，**越接近有序，插入排序的效率就越高**，从而可以达到优化的效果。

### 图解

![图片来源于网络](https://i-blog.csdnimg.cn/blog_migrate/4f3d6ca502bddeb2b466cd2c2054be55.gif#pic_center)

可以看到每次减小gap的规律是将原先的gap/2，但事实上这只是其中一种处理方法，并不说明这是最优解。

### C语言代码分析

```c
//与插入排序类似，只是插入排序的间隔是1，而希尔排序的间隔是gap

//第一种思想：依次排序
//排完一组后，再排下一组
void ShellSort1(int arr[], int n)
{
	int gap = 3;//任意一个想要的间隔
	for (int j; j < gap; j++)
	{
		for (int i = gap; i < n; i += gap)
		{

			int end = i - gap;
			int tmp = arr[end + gap];
			while (end >= 0)
			{
				if (tmp >= arr[end])
				{
					arr[end + gap] = tmp;
					end -= gap;
				}
				else
				{
					break;
				}
			}
			arr[end + gap] = tmp;
		}
	}


}

//第二种思想：多组并排
void ShellSort2(int arr[], int n)
{
	int gap = 3;//任意一个想要的间隔
	
		for (int i = gap; i < n-gap; i ++)
		{

			int end = i;
			int tmp = arr[i + gap];
			while (end >= 0)
			{
				if (tmp >= arr[end])
				{
					arr[end + gap] = tmp;
					end -= gap;
				}
				else
				{
					break;
				}
			}
			arr[end + gap] = tmp;
		}
}

//gap越大，跳得越快，但一次排下来最无序
//gap越小，跳得越慢，但一次排下来更有序
```

### 注意

希尔排序实际上是个相当复杂的排序算法，这主要是跟它的步长序列gap到底该如何取、后续应该减小有关。这其中涉及到很多的数学分析以及数学公式，我们可以参考严蔚敏老师的解读：

![image-20240819192423736](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240819192423736.png)

以及殷人昆老师：

![image-20240819192455945](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240819192455945.png)

所以，本篇文章仅对其基本的算法思想和代码编写进行解析，如有兴趣深究希尔排序，各位读者们可以自行上网搜索有关知识~

### 时间复杂度

一般情况下，希尔排序的时间复杂度可以表示为：

- 最好情况（已排序的情况）：**O(n log n)**
- 平均情况：取决于步长序列的选择，通常为**O(n^1.3^)-O(n^2^)**之间。
- 最坏情况：**O(n^2^)**

希尔排序通过逐步减少步长来实现排序，**初始的大步长使得数组元素可以较快地达到部分有序状态，最终通过小步长的插入排序完成排序**。所以时间复杂度的具体分析也就取决于步长序列。

这里针对平均情况，我们进行一下简单的具体分析：

希尔排序的平均情况时间复杂度是比较复杂的。在实际应用中，常见的步长序列如**希尔建议的序列**（1, 3, 7, ..., 2^k-1）或者**Hibbard序列**（1, 3, 7, 15, ..., 2^k-1^）等，它们的时间复杂度通常就在**O(n^1.3^)-O(n^2^)**之间，这是经过数学算出来的结果。这些序列被设计为逐渐减小，从而在较早阶段快速减少逆序对的数量，然后在最后阶段完成排序。

总体来说，希尔排序的性能**高度依赖于步长序列**的选择。**良好的步长序列可以显著改善排序的效率**，使得平均情况下的时间复杂度能够在O(n^1.3)左右，而不好的选择则可能导致接近最坏情况的性能。

### 稳定性

鉴于希尔排序会改变前后元素的相对位置，所以：**不稳定**

## 选择排序

### 算法思想

选择排序的思想与插入排序其实有异曲同工之处，它们都会对数据进行比较和交换，但是它们也还是有很大的差别：插入排序是两两元素之间进行比较，而选择排序是将最值的元素同其他元素依次进行比较，从而按照最大（或最小）、第二大、第三大这样的顺序进行数组的重组。

它的大致步骤如下：

1. 第一次从待排序的数据元素中选出**最小（或最大）**的一个元素，存放在序列的起始(末尾)位置
2. 然后选出**次小(或次大)**的一个元素，存放在最大(最小)元素的下一个位置
3. 重复这样的步骤直到全部待排序的数据元素排完 

### 图解

![选择排序](C:/Users/SKRRAP~1/AppData/Local/Temp/7zO4148AB74/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F.gif)

### C语言代码分析

```c
//选择排序
void SelectSort1(int* a, int n);
void SelectSort2(int* a, int n);

//1.只进行最小值或者最大值的交换
void SelectSort1(int* a, int n)
{
	int left = 0;
	int right = n - 1;
	while (left < right)
	{
		int min = left;//指定目前最小值为第一个元素
		for (int i = left + 1; i <= right; i++)
		{
			if (a[i] < a[min])//如果有比目前最小值更小的元素，就更新最小值，进行交换
			{
				min = i;
			}
		}
		if (min != left)//如果最小值不是第一个元素，就进行Swap交换
		{
			int temp = a[min];
			a[min] = a[left];
			a[left] = temp;
		}
		left++;//每完成一次交换，左指针向右移动一位，进行下一次交换
	}
}


//2.最小值和最大值同时进行交换，优点是减少了交换次数，在一定程度上提高了效率
void SelectSort2(int* a, int n)//选择排序
{
	int left; int right = n - 1;//左右指针
	while (left < right)
	{
		int min = left, max = right;//最小值和最大值的下标
		for(int i=left+1;i<=right;i++)
		{
			if (a[i] < a[min])//找最小值
				min = i;
			if (a[i] > a[max])//找最大值
				max = i;
		}
		if (min != left)
		{
			//进行一次Swap交换
			int temp = a[min];
			a[min] = a[left];
			a[left] = temp;
		}
		//如果最大值和最小值相等，说明最大值和最小值是同一个元素，只需要进行一次交换
         //如果继续交换max，就会将最小值交换到末尾位置。
		if (left = right)
		{
			right = min;
		}
		left++;
		right--;

}
```

### 时间复杂度

选择排序的最优时间复杂度、平均时间复杂度和最坏时间复杂度均为**O(n^2^)**。

### 稳定性

鉴于选择排序会改变前后元素的相对位置，所以：**不稳定**

## 冒泡排序

![image-20240819202503811](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240819202503811.png)

接下来我们要介绍的是排序算法中极为标志性，并且经常在教材中作为经典案例出现的——冒泡排序。

### 算法思想

冒泡排序(Bubble sort)的算法思想也是较为容易去理解的，我们参照冒泡这一物理现象，会发现，往往大的气泡都会往上运动，而小的气泡往往都在下方。冒泡排序的名字也就是这么由来的。它的算法步骤大致如下：

1. 从数组的开头开始，将第一个数据与第二个数据进行比较，按照指定的比较思想（大的放前面or小的放前面）完成交换操作
2. 再将此时的第二个数据与第三个数据再次进行步骤1中的操作，以此类推，直到比较完最后两个数据
3. 此时的数组如果不是完全有序，那么从头开始进行步骤1和步骤2的操作，直到完全有序。

### 图解

![冒泡排序](C:/Users/SKRRAP~1/AppData/Local/Temp/7zO414BC928/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.gif)

### C语言代码分析

```c
void BubbleSort(int* a, int n)
{
	bool exchange = false;//标记是否发生交换
	for(int j=0;j<n;j++)
	{
		for (int i = 1; i < n-j; i++)
		{
			//如果前一个元素大于后一个元素，交换
			if (a[i - 1] > a[i])
			{
				int temp = a[i - 1];
				a[i - 1] = a[i];
				a[i] = temp;
			}
			if(exchange == false)//如果没有发生交换，说明此时已经有序，那么就直接跳出
			{
				break;
			}
		}
	}

}
```

### 时间复杂度

我们可以看出，实际上冒泡排序是华而不实的一种排序算法。它在数据较少或者较为有序的时候，可以有很好的效率，但是一旦数据多起来或者较为无序，那么需要重复的次数就会大幅度增加，从而后期乏力，效率降低。

- 在序列完全有序时，冒泡排序只需遍历一遍数组，不用执行任何交换操作，时间复杂度为**O(n)**。

- 在最坏情况下，冒泡排序要执行**(n-1)n/2**次交换操作，时间复杂度为**O(n^2^)**。

- 冒泡排序的平均时间复杂度为**O(n^2^)**。

### 稳定性

鉴于冒泡排序不会改变前后元素的相对位置，所以：**稳定**

## 堆排序

堆排序基于一种常见的**二叉树结构**：**堆**

我们前面讲到选择排序，它在待排序的n个记录中选择一个最小的记录需要比较n一1次。本来这也可以理解，查找第一个数据需要比较这么多次是正常的，否则无法知道它是最小的记录。
可惜的是，这样的操作并没有把每一趟的比较结果保存下来，**在后一趟的比较中，有许多比较在前一趟已经做过了**，但由于前一趟排序时未保存这些比较结果，所以后一趟排序时又重复执行了这些比较操作，因而记录的比较次数较多。

那么我们有什么办法可以用来解决这样的重复比较的问题呢？

那么堆排序就由此而生了。简单来说，堆的性质包括如下几点：

堆（Heap）是一种特殊的树形数据结构，通常用作优先队列。堆排序算法利用了堆的性质来实现排序。堆的性质总结如下：

1. **完全二叉树**：堆是一种完全二叉树（Complete Binary Tree），即除了最后一层外，每一层的节点都是满的，且最后一层的节点从左到右依次排列。
2. **堆的有序性**：
   - **大顶堆（Max-Heap）**：对于每一个节点 `i`，都满足 `A[i] ≥ A[2i + 1]` 且 `A[i] ≥ A[2i + 2]`（如果子节点存在）。即，**父节点的值总是大于或等于其子节点的值。**
   - **小顶堆（Min-Heap）**：对于每一个节点 `i`，都满足 `A[i] ≤ A[2i + 1]` 且 `A[i] ≤ A[2i + 2]`（如果子节点存在）。即，**父节点的值总是小于或等于其子节点的值。**
3. **堆的高度**：一个包含 `n` 个节点的堆的高度为 `O(log n)`。因为堆是完全二叉树，树的高度和节点数量的对数成正比。

根据堆的有序性和完全二叉树的性质，我们得知将其用在排序上是可行的，并且还能够有效减少重复比较的次数，这何乐而不为呢？

1964年，Floyd和Williams发明了堆这种数据结构，同时也发明了堆排序这种算法。

### 算法思想

鉴于堆的有序性，我们在进行堆排序时首先要构建一个大顶堆或者小顶堆，这里为了方便计算，我们统一为大顶堆。在大顶堆的性质下，可能会有人疑问：既然这个堆已经满足了有序性，那还需要排序什么呢？直接返回不就行了吗？其实不然。我们所知道的有序性的堆只是针对子节点与父节点之间的大小关系，例如以下堆：

![image-20240821095351830](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240821095351830.png)

我们可以看到，它确实满足大顶堆的性质：父节点永远大于子节点。但是当我们根据二叉树的遍历来进行输出时，会发现同一个父节点的子节点之间以及其中一个子节点的子节点实际上是无序的，例如60和10，它们之间是大于的关系；而60的子节点又都比10大，那么在遍历的时候，自然就不有序了。

所以堆实际上并不是完全有序的，而我们使用堆排序这个算法，也并非是根据这样的特征来进行的。我们直接看它的算法步骤：

1. 首先建立大顶堆，然后将堆顶的元素取出，作为最大值，与数组尾部的元素交换，并维持残余堆的性质（也就是将剩余n-1个元素继续构成一个堆）；
2. 之后将堆顶的元素取出，作为次大值，与数组倒数第二位元素交换，并维持残余堆的性质；
3. 以此类推，在第**n-1**次操作后，整个数组就完成了排序。

我们可以看到，实际上堆排序的核心思想就是将第一个根节点（最大值）与数组末尾的元素来进行交换（**目的是为了构建无需新开辟空间就能直接构建有序数组，末尾元素被交换后也不会影响大顶堆的重新构建**），然后重新构造堆，那么此时的第二个根节点就仅次于第一个根节点的大小，这么以此类推，最终将所有节点根据大、次大、第三大的顺序排序在数组中，那么也就成功构建出了有序的数组。

### 图解

![img](https://upload.wikimedia.org/wikipedia/commons/1/1b/Sorting_heapsort_anim.gif)

### C语言代码分析

```c
void AdjustDown(HPDataType* a, int n,int parent)//向下调整算法
{
    int child = parent * 2 + 1;
    while (child < n)
    {
        //选择左右孩子中大的那一个
        if (child+1 < n && a[child+1] > a[child])//如果右孩子存在并且右孩子大于左孩子
        {
            ++child;
        }
        if (a[child] > a[parent])//如果孩子大于父亲
        {
            Swap(&a[child] , &a[parent]);
            parent = child;
            child = parent * 2 + 1;
        }
        else//如果孩子小于父亲
        {
            break;
        }

    }
}


void HeapSort(int* a, int n)
{
    /*for (int i = 1; i < n; i++)
    {
        AdjustUp(a, i);
    }*/
    for (int i = (n - 1 - 1) / 2; i >= 0; i++)//从最后一个非叶子节点开始调整
    {
        AdjustDown(a, n, i);
    }

    int end = n-1;
    while (end > 0)//每次将堆顶元素与最后一个元素交换，然后调整堆
    {
        Swap(&a[end], &a[0]);
        AdjustDown(a, end, 0);
        end--;
    }
}
```

### 时间复杂度

我们发现堆的算法实际上是基于二叉树排序的，并且在最坏情况和最好情况下的堆排序都是同一量级的操作，所以我们得出其时间复杂度为：**O(n logn)** 

### 稳定性

鉴于堆排序会改变前后元素的相对位置，所以：**不稳定**

## **快速排序**

接下来我们将要介绍的是排序中最为重要的算法之一——快速排序。

**快速排序**（英语：Quicksort），又称**分区交换排序**（partition-exchange sort），最早由[东尼·霍尔](https://zh.wikipedia.org/wiki/東尼·霍爾)提出。快速排序通常明显比其他算法更快，因为它的内部循环可以在大部分的架构上很有效率地达成。我们直接来分析它的算法思想。

### 算法思想与图解

我们首先直接来看算法步骤，再分析其原理和目的

1. 首先确定一个基准值，基准值一般选最左边或者最右边的
2. 然后使用左右指针对数据和基准值进行大小比较
3. 比基准值小的放左边，比基准值大的放右边，从而使得最终基准值的左边比其小，右边比其大
4. 递归重复此步骤，注意基准值不能重复，直到完全有序

![img](https://www.runoob.com/wp-content/uploads/2019/03/quickSort.gif)

具体的动画分析可以看这：[快速排序算法动画演示_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1q64y1S7Ax/?vd_source=c74ab8715cb32f0e72233350d38cc1c9)

我们首先来对基准值的选择进行分析：

**通常我们都会选择最左边或者最右边的基准值**，这是最不需要多想的选择方法；

但是往往我们需要考虑时间效率，这样选择的话，时间效率是怎样的呢？我们知道最左边和最右边的数有可能是整个数据组中最大或者最小的数，而一轮快速排序的最终目的就是使用基准值将数据分为比其大和比其小的两部分，那么如果记住基准值本身就是一个最值，排序完之后必定也只会在最前或者最后一个位置，这样就会进行浪费的比较，从而降低效率。

![image-20240823141049790](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240823141049790.png)

如果我们需要规避这种最坏的情况，我们可以使用**随机基准值**或者**三数取中法**。这样能够有效规避最坏情况的发生，但并非绝对事件。

```c
//1.随机取基准值
//随机选基准值，从而可以有效减小最坏情况的概率 
int randindex = rand() % (right - left + 1) + left;
Swap(&a[randindex], &a[left]);

//2，三数取中
int GetMid(int* a, int left, int right)
{
	int mid = (left + right) / 2;
	if (a[left] < a[mid])//左边和中间比较
	{
		if(a[mid]<a[right])
			return mid;
		else if (a[left] < a[right])
			return right;
		else
			return left;
	}
	else//左边和中间比较
	{
		if (a[mid] > a[right])
			return mid;
		else if (a[left] > a[right])
			return right;
		else
			return left;

	}
}
```

从基准值的选择我们其实也可以看出，实际上快速排序的核心思想就是**使用基准值，将数据组分成两份**。这也是它**分区交换排序**名字的由来。分析分区原理，**只要一直不断地进行分区操作，那么最后每个数都可以成为一次基准值，也就可以达到每个数的左边都比其小，右边都比其大，那么整体来看就已经实现了完全有序。**

### C语言代码分析

- 霍尔快排

```c
void QuickSort1(int* a, int left, int right)
{
	if (left >= right)
		return;

	//随机选基准值，从而可以有效减小最坏情况的概率 
	int randindex = rand() % (right - left + 1) + left;
	Swap(&a[randindex], &a[left]);

	int key = left;//选择最左边为基准值
	while (left < right)
	{
		//右边找小的
		while (a[right] >= a[key])
			right--;
		//左边找大的
		while (a[left] <= a[key])
			left++;

		Swap(&a[left], &a[right]);
	}
	Swap(&a[key], &a[left]);
	//二叉树的递归方式
	QuickSort1(a, key, left - 1);//递归左边
	QuickSort1(a, left + 1, right);//递归右边
}
//霍尔单趟
int PartSort1(int* a, int left, int right)
{
	if (left >= right)
		return;

	//随机选基准值，从而可以有效减小最坏情况的概率 
	int randindex = rand() % (right - left + 1) + left;
	Swap(&a[randindex], &a[left]);

	int key = left;//选择最左边为基准值
	while (left < right)
	{
		//右边找小的
		while (a[right] >= a[key])
			right--;
		//左边找大的
		while (a[left] <= a[key])
			left++;

		Swap(&a[left], &a[right]);
	}
	Swap(&a[key], &a[left]);
	return left;

}
```

### 注意

#### 二叉树思想

我们观察上述的代码，会发现**我们的分区思想与二叉树的思想略有相似**：将基准值看成根节点，那么它的左子树——也就是左边的部分绝对比其小；类似，右子树也绝对比其大（都反过来也可）——实际上霍尔当时就是根据二叉树的思想从而发明了这样一种排序的算法。

#### 左右指针相遇的逻辑

1. **初始化指针**：
   - 左指针从数组的起始位置开始向右移动，寻找一个大于基准值的元素。
   - 右指针从数组的末尾开始向左移动，寻找一个小于基准值的元素。

2. **移动指针**：
   - 左指针向右移动，直到找到一个大于等于基准值的元素。
   - 右指针向左移动，直到找到一个小于等于基准值的元素。

3. **指针相遇**：
   - 当左右指针相遇时，意味着左指针的位置是一个元素大于基准值的位置，而右指针已经通过其他元素找到了一个小于基准值的元素。此时可以认为，**左指针的位置应该是大于或等于基准值的（可能因为左指针已经停止在一个比基准值小的元素上），而右指针的位置则是小于或等于基准值的。**

#### 为什么相遇节点永远小于基准值

在理想的情况下，通过上述移动，左右指针不会交叉的情况下，最终会在一个位置相遇，这个位置可能就是基准值的位置，也可能比基准值小。而这个位置的元素比基准值小的原因是基于以下几点：

1. **分区约束**：

   - 根据右边先走，左边再走的顺序，左右指针最终需要相遇前会有以下两种情况：

     1.右指针找到小的，左指针没有找到大的，那么此时继续移动二指针就会相遇。

     2,右指针没有找到小的，继续移动直到遇到了左指针，**鉴于左指针本身就比基准值要小或者相等（才会停下）**，所以此时的相遇位置就可以是比基准值要小。

     无独有偶，当左边先走，右边再走时就有可能遇见比基准值大的相遇位置。

2. **基准值的定义**：

   - 最终将会把基准值放在左右指针交会的位置的元素上。这个位置的特性就是：在其左边的都是小于基准值的元素，而在其右边的都是大于基准值的元素。

因此，尽管左右指针可能在不等于基准值的元素上相遇，实际上通过合并数据的方式能整理出期望的排序效果。因此，它并不意味着相遇位置的元素永远小于基准值，而是说在执行分区后，基准值应该放在那个位置以满足排序的条件。

### 算法优化

快速排序除了霍尔发明的最初的一种算法，实际上还有改进算法。

- **挖坑法**

挖坑法的实质是不断变换坑位，这个坑位最终是用来存放基准值的位置。而在算法中我们将看到坑位始终是根据左右指针来进行定位的，因此当坑位要存放基准值也就是单趟结束的时候，左右指针会相遇在基准值的坑位。左右指针的移动也是根据同基准值的大小来决定的。

这个算法的好处是有助于我们更好地理解快排的本质，从而优化算法。

```c
//挖坑法的实质就是不断变基准值的位置，直到找到基准值的位置
void QuickSort2(int* a, int left, int right)
{
	if (left >= right)
		return;

	int begin = left, end = right;

	//三数取中
	int mid = GetMid(a, left, right);
	if (left != mid)
		Swap(&a[left], &a[mid]);

	int key = a[left];
	int hole = left;//挖坑位置

	while (left < right)
	{
		//右边找小的
		while (a[right] >= a[key])
			right--;
		a[hole] = a[right];//填坑
		hole = right;

		//左边找大的
		while (a[left] <= a[key])
			left++;
		a[hole] = a[left];//填坑
		hole = left;

		Swap(&a[left], &a[right]);
	}
	Swap(&a[key], &a[left]);
	//二叉树的递归方式
	QuickSort1(a, key, left - 1);//递归左边
	QuickSort1(a, left + 1, right);//递归右边
}

//挖坑单趟
void PartSort2(int* a, int left, int right)
{
	
	//三数取中
	int mid = GetMid(a, left, right);
	if (left != mid)
		Swap(&a[left], &a[mid]);

	int key = a[left];
	int hole = left;//挖坑位置

	while (left < right)
	{
		//右边找小的
		while (a[right] >= a[key])
			right--;
		a[hole] = a[right];//填坑
		hole = right;

		//左边找大的
		while (a[left] <= a[key])
			left++;
		a[hole] = a[left];//填坑
		hole = left;
		
	}
	a[hole] = key;
	return hole;
}
```

- **前后指针法**

![img](https://developer.qcloudimg.com/http-save/yehe-10923276/591d810d12c1a4975e8daef61a774794.gif)

前后指针法使用cur和prev前后两个指针进行移动，规则如下：

- A.cur找到比基准值小的值，prev++，再将cur与prev位置的值交换，cur++
- B.cur找到比基准值大的值，cur++
- 当cur越界（识别完所有的数据）时，结束所有的移动，将基准值放入此时prev的位置。

我们分析，在这两种情况下，prev要么就是紧跟cur，两个指针一直依附着对方前进，要么就是中间间隔的数都比基准值要大；同时它也实现了快排的核心思想：比基准值大的放右边，比基准值小的放左边。

```c
//第三种是前后指针法
//前后指针法的实质是通过比较后指针和基准值的大小，
//然后满足大小条件时进行前后指针交换
//交换的原则就是把小的放在前边，大的放在后边
void QuickSort3(int* a, int left, int right)
{
	int mid = GetMid(a, left, right);
	if (mid != left)
		Swap(&a[left], &a[mid]);
	int key = left;
	
	int prev = left;
	int cur = left + 1;
	while (cur <= right)
	{
		if (a[cur] <a[key] && ++prev != cur)
		{
			Swap(&a[cur], &a[prev]);
		}
		cur++;
		
	}
	Swap(&a[prev], &a[key]);
	key = prev;

	return key;
    
}

//前后指针单趟
int PartSort3(int* a, int left, int right)
{
	int mid = GetMid(a, left, right);
	if (mid != left)
		Swap(&a[left], &a[mid]);
	int key = left;

	int prev = left;
	int cur = left + 1;
	while (cur <= right)
	{
		if (a[cur] < a[key] && ++prev != cur)
		{
			Swap(&a[cur], &a[prev]);
		}
		cur++;

	}
	Swap(&a[prev], &a[key]);
	key = prev;

	return key;

}

```

- **非递归快排**

非递归版本主要通过**显式栈**来模拟递归调用栈。

使用非递归的原因：当数据过多的时候，递归算法就会跑不起来——**递归需要建立栈帧，当建立了过多的栈帧就会出现栈溢出的情况。**

1. **初始化栈**：创建一个栈来保存需要处理的数组区间。
2. **入栈**：将整个数组的左右边界（即数组的起始和结束索引）入栈。
3. **循环处理**：
   1. 从栈顶弹出一对左右边界。
   2. 使用这些边界对数组进行分区，找到分区的中间点（即分区点）。
   3. 将分区点两侧的左右边界分别入栈，表示后续需要处理的子数组。
   4. 如果某个子数组的元素数量少于等于1，则不需要入栈处理。
4. **结束**：当栈为空时，所有区间都已经处理完毕，排序完成。

```c
//非递归实现快排
void QuickSortNoR(int* a, int left, int right)
{
	ST s;
	STInit(&s);
	STPush(&s, left);//先将左右边界入栈
	STPush(&s, right);

	while (STEmpty(&s))
	{
		//取出左右边界
		int begin = STTop(&s);
		STPop(&s);
		int end = STTop(&s);
		STPop(&s);
		//使用一次单趟的快排得到第一次的基准值
		int key = PartSort3(a, begin, end);
		//将基准值的左右边界入栈
		if (key + 1 < end)
		{
			STPush(&s, end);
			STPush(&s, key + 1);
		}
		if (begin < key-1)
		{
			STPush(&s, key-1);
			STPush(&s, begin);
		}
	}

	STDestroy(&s);
}
```

**代码解析**

1. **S结构体**：用来保存左右边界索引。
2. **PartSort3函数**：选择数组的最右边元素为基准元素，通过交换使得基准元素的左侧都是小于等于它的元素，右侧都是大于它的元素。返回值是基准元素的最终位置。

**这个算法是利用栈模拟递归过程，适用于不能使用递归的环境或递归深度较大的情况。**

### 时间复杂度

关于快速排序为什么是最好的排序算法之一，肯定与它优秀的时间效率扯不开关系。这里我们直接看维基对于其平均时间复杂度的分析：

![image-20240823162548748](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240823162548748.png)

可以看到，快速排序从根本上就能够良好的减少遇见最坏情况的概率，而它的最坏情况实际上也坏不到哪去，如此优秀的排序机制也为它奠定了基础和不可动摇的地位。

最坏情况：**O(n^2^)**

最好情况：**O(n logn)**

### 稳定性

鉴于快速排序会改变前后元素的相对位置，所以：**不稳定**

## 归并排序

归并排序从字面上来看，它的大致核心应与归并有关——归并拆分开来，变成归类和合并，**归类则是将数组进行有序化，合并则是将两个有序的数组进行合并变成一个有序的数组。**

它的特点在于并不是一开始就将整个数组进行归类和调整，而是以一定的间隔数分成多次小的排序，最后再逐渐将小的排序的范围变大，最后变大到整个数组时，已经完全有序。

### 算法思想和图解

**递归法（Top-down）**

1. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列
2. 设定两个指针，最初位置分别为两个已经排序序列的起始位置
3. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置
4. 重复步骤3直到某一指针到达序列尾
5. 将另一序列剩下的所有元素直接复制到合并序列尾

**迭代法（Bottom-up）**

原理如下（假设序列共有n个元素)

1. 将序列每相邻两个数字进行归并操作，形成**Ceil(n/2)**个序列，排序后每个序列包含两/一个元素
2. 若此时序列数不是1个则将上述序列再次归并，形成**Ceil(n/4)**个序列，每个序列包含四/三个元素
3. 重复步骤2，直到所有元素排序完毕，即序列数为1

界定比较的数据个数：一般按照2的倍数增长：两个互相比较、四个互相比较、八个互相比较...下图可以很好地说明这种方法

![undefined](https://upload.wikimedia.org/wikipedia/commons/c/cc/Merge-sort-example-300px.gif)

或者这样看：

![归并排序](C:/Users/SKRRAP~1/AppData/Local/Temp/7zO491AA350/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.gif)

上图根据颜色的不同进行分组，可以看到先分成两个数据。再分成四个...

### C语言代码分析

```c
void _MergeSort(int* a, int begin, int end, int* tmp)
{
	int mid = (begin + end) / 2;//中间值
	//（提问：如果不是2的倍数会不会有错——不会，归并本身和元素个数无关,基于"/"的特性）
	if (begin >= end)
	{
		return;
	}
	_MergeSort(a, begin, mid, tmp);//先从左边开始
	_MergeSort(a, mid + 1, end, tmp);//再从右边开始

	int begin1 = begin, end1 = end;//左边的起始位置和结束位置
	int begin2 = mid + 1, end2 = end;//右边的起始位置和结束位置
	int i = begin;//这里不能给0，因为递归时会多次调用
	while (begin1 <= end1 && begin2 <= end2)
	{
		if (a[begin1] < a[begin2])
		{
			tmp[i++] = a[begin1++];
		}
		else
		{
			tmp[i++] = a[begin2++];
		}
	}
	while (begin1 <= end1)//如果左边还有剩余
	{
		tmp[i++] = a[begin1++];
	}
	while (begin2 <= end2)//如果右边还有剩余
	{
		tmp[i++] = a[begin2++];
	}
	memcpy(tmp + begin, a + begin, sizeof(int) * (end - begin + 1));//将排好序的拷贝回去
}

void MergeSort(int* a, int n)
{
	int* tmp = (int*)malloc(sizeof(int) * n);
	if (tmp == NULL)
	{
		printf("malloc fail\n");
		return;
	}
	_MergeSort(a, 0, n - 1, tmp);

	free(tmp);
}
```

非递归的归并排序

```c
//非递归归并
void MergeSortNonR(int* a, int n)
{
	int* tmp = (int*)malloc(sizeof(int) * n);
	//归并排序为什么不能用栈？——因为递归的时候需要保存现场，栈不方便
	if (tmp == NULL)
	{
		printf("malloc fail\n");
		return;
	}
	//对于非递归，我们可以两两进行排序，然后拷贝回去再进行四四排序，直到全部排序
	int gap = 1;//每组的数据个数
	while (gap < n)
	{
		for (int i = 0; i < n; i += 2 * gap)
		{
			int begin1 = i, end1 = i + gap - 1;//左边的起始位置和结束位置
			int begin2 = i + gap, end2 = i + 2 * gap - 1;//右边的起始位置和结束位置
			
			//考虑越界情况
			//if (end1 >= n)
			//{
			//	end1 = n - 1;
			//	begin2 = n;//这里不能给n-1，因为下面会++，会越界
			//	end2 = n - 1;
			//}
			//else if (begin2 >= n)
			//{
			//	begin2 = n;
			//	end2 = n - 1;
			//}
			if (end1 >= n || begin2 >= n)
			{
				break;
			}
			else if (end2 >= n)
			{
				end2 = n - 1;
			}

			int j = i;//这里不能给0，因为递归时会多次调用
			while (begin1 <= end1 && begin2 <= end2)
			{
				if (a[begin1] < a[begin2])
				{
					tmp[j++] = a[begin1++];
				}
				else
				{
					tmp[j++] = a[begin2++];
				}
			}
			while (begin1 <= end1)//如果左边还有剩余
			{
				tmp[j++] = a[begin1++];
			}

			while (begin2 <= end2)//如果右边还有剩余
			{
				tmp[j++] = a[begin2++];
			}
			//拷贝
			memcpy(tmp + i, a + i, sizeof(int) * (end2 - i + 1));
		}
		gap *= 2;
	}
	free(tmp);
}
```

### 时间复杂度

**O(nlogn)**

### 稳定性

鉴于归并排序会改变前后元素的相对位置，所以：**不稳定**

### 分治思想

我们发现快速排序和归并排序都使用了一种**分治**的思想，这里对其进行简单介绍一下，以便更好地理解归并排序

![image-20240831155655433](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240831155655433.png)

![image-20240831155715564](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240831155715564.png)

分治模式在每层递归时都有三个步骤：
1.分解原问题为若干子问题，这些子问题是**原问题的规模较小的实例**，也就是说实际上子问题也可以看作是一个原问题。
2.解决这些子问题，递归地求解各子问题。然而，若子问题的规模足够小，则直接求解。
3.合并这些子问题的解成原问题的解。
归并排序算法完全遵循分治模式。直观上其操作如下：

1. 分解：分解待排序的n个元素的序列成各具n/2个元素的两个子序列。
2. 解决：使用归并排序**递归**地排序两个子序列。
3. 合并：合并两个已排序的子序列以产生已排序的答案。

所以从这个角度来看实际上分治思想也是基于递归的思想来解决问题的。所以间接地也能帮助我们理解递归的思想。

![image-20240823222250864](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240823222250864.png)

在[计算机科学](https://zh.wikipedia.org/wiki/计算机科学)中，**分治法**（英语：Divide and conquer）是建基于多项分支[递归](https://zh.wikipedia.org/wiki/递归)的一种很重要的算法[范型](https://zh.wikipedia.org/wiki/範式)。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。

![image-20240817162346875](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240817162346875.png)

分治法能解决的问题一般有如下特征：

- 该问题的规模缩小到一定的程度就可以容易地解决。
- 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质，利用该问题分解出的子问题的解可以合并为该问题的解。
- 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子问题。

总的来说，分治法也可以被称作一种算法，它是一种基于递归的、“分而治之”的算法思想。

## 计数排序

顾名思义：统计每个数据出现的次数。

### 算法思想

我们根据《算法导论》中给出对于计数排序的讨论：

对每一个输入元素 **x**, 确定小于 **x** 的元素个数。利用这一信息，就可以直接把 **x** 放到它在输出数组中的位置上了。例如，如果有 17 个元素小于 **x** , 则 **x** 就应该在第18个输出位置上。当有几个元素相同时，这一方案要略做修改。因为不能把它们放在同一个输出位置上。

它的工作过程分为三个步骤：

1. 计算每个数出现了几次；
2. 求出每个数出现次数的 [前缀和](https://oi-wiki.org/basic/prefix-sum/)；
3. 利用出现次数的前缀和，从右至左计算每个数的排名。

### 图解

![counting sort animate example](https://oi-wiki.org/basic/images/counting-sort-animate.svg)

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/45de2ac506a7f9fdf61935e2c3ec082c.gif#pic_center)



#### C语言代码分析

```c
#define CRT_SECURE_NO_WARNINGS 1
//计数排序
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

void CountingSort(int arr[], int size)
{
	//找到数组中的最大值和最小值

	int max = arr[0];
	int min = arr[0];
	for (int i = 1; i < size; i++)//进行
	{
		if (arr[i] > max)//如果元素大于此时的最大值，则更新最大值
			max = arr[i];
		if (arr[i] < min)//如果元素小于此时的最小值，则更新最小值
			min = arr[i];
	}

	//创建计数数组，并初始化为0
	int range = max - min - 1;
	int* count = (int*)calloc(range, sizeof(int));

	//统计每个元素的出现次数
	for (int i = 1; i < size; i++)
	{
		count[arr[i] - min]++;//将元素的值作为下标，出现的次数作为值
	}

	//进行累加操作
	for (int i = 1; i < range; i++)
	{
		count[i] += count[i - 1];
	}

	//创建输出数组，并将元素按照排序结果依次放入
	int* output = (int*)malloc(size * sizeof(int));
	for (int i = size - 1; i >= 0; i--)
	{
		output[count[arr[i] - min] - 1] = arr[i];//将元素放入输出数组中
		count[arr[i] - min]--;//将元素的出现次数减1,符合C语言下标规则
	}

	//将排序结果放回原数组
	for (int i = 0; i < size; i++)
	{
		arr[i] = output[i];
	}

	free(count);
	free(output);
}
```

### 时间复杂度

我们发现这种算法实际上并没有进行比较——它是一个非比较排序算法。它主要进行的是一个分类的操作，将相同的数分在一类，在进行完分类后，再针对分类出来的代表数进行整体排序。但实际上这样的排序会有一个缺陷——如果相同的数过少，或者说整个数据组的同一性过小，那么实际上分类过程的意义也就会随之变小——从而还是主要依靠排序来进行算法的完成。这里我们就会谈及计数排序的局限性——**它适用于范围集中且范围不大的整形数组排序。**

![image-20240817171439272](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240817171439272.png)

计数排序的下界优于**O（nlogn）**，因为它并不是一个比较排序算法。事实上，它的代码中完全没有输人元素之间的比较操作。相反，计数排序是使用输人元素的实际值来确定其在数组中的位置。当我们脱离了比较排序模型的时候，**O（nlogn）**这一下界就不再适用了。

我们一般根据数组的范围来判断其时间复杂度，为此我们可以给出大致的复杂度：

**O(n+w)**，其中w代表待排序数据的值域大小。

### 稳定性

计数排序的一个重要性质就是它是稳定的：具有相同值的元素在输出数组中的相对次序与它们在输人数组中的相对次序相同。也就是说，对两个相同的数来说，在输入数组中先出现的数，在输出数组中也位于前面。

计数排序的稳定性很重要的另一个原因是：计数排序经常会被用作基数排序算法的一个子过程。我们将在下一节中看到，为了使基数排序正确运行，计数排序必须是**稳定的**。

## 桶排序

### 算法思想

桶排序（BucketSort)，也被叫做箱排序，它将整个数据组分为n个相同大小的子区间，这类子区间或称为**桶**。输入数据是均匀、独立分布的，所以一般不会出现一个桶中装有过多数据的情况。作为一种排序算法，它会对每个桶中的数进行排序，然后直接遍历桶，最终就可以按照次序输出数据。
它的算法步骤大概如下所示：

1. 设置定量数组作为每个桶的容量大小
2. 遍历数据组，并将数据一个一个放到对应桶中
3. 对非空桶中的数据进行排序
4. 最后将数据按照大体排序放回原来序列中

### 图解

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0b0aa66f7d89e553bef6724dcca87c56.gif#pic_center)

### C语言代码解析

```c
#define CRT_SECURE_NO_WARNINGS 1
//桶排序
#include <stdio.h>
#include <stdlib.h>	

#define MAX 1000
#define BUCKET_NUM 10

//建桶中节点
struct BNode
{
	int data;
	struct Node* next;
};

//建桶
struct BNode* CreateNode(int data)
{
	struct BNode* newNode = (struct BNode*)mlooc(sizeof(struct BNode));
	newNode->data = data;
	newNode->next = NULL;
	return newNode;
}

//插入节点到链表中
void insertNode(struct BNode* head, struct BNode* newNode)
{
	struct BNode* p = head;
	while (p->next != NULL)
	{
		p = p->next;
	}
	p->next = newNode;
}

//桶排序
void BucketSort(int arr[], int n)
{
	struct BNode* bucket[BUCKET_NUM];
	for (int i = 0; i < BUCKET_NUM; i++)
	{
		bucket[i] = CreateNode(0);//创建多个桶
	}
	for (int i = 0; i < n; i++)
	{
		int index = arr[i] / BUCKET_NUM;//确定元素所在桶的位置
		struct BNode* newNode = CreateNode(arr[i]);
		insertNode(bucket[index], newNode);//插入节点到链表中
	}
	for (int i = 0; i < BUCKET_NUM; i++)//对每个桶进行排序
	{
		struct BNode* p = bucket[i]->next;
		while (p != NULL)
		{
			printf("%d ", p->data);
			p = p->next;
		}
	}
}
```

### 时间复杂度

桶排序的时间复杂度取决于以下几个因素：
1. **将数据分配到桶的时间**
2. **对每个桶内的数据进行排序的时间**
3. **合并所有桶中的数据的时间**

假设我们有 `n` 个元素需要排序，并且我们使用了 `k` 个桶。

#### 1. 将数据分配到桶的时间复杂度

将每个元素放入对应的桶中的操作通常是一个线性的操作。对于每一个元素，确定它所属的桶位置的时间是 O(1) 的，总的时间复杂度为 O(n)。

#### 2. 对每个桶内的数据进行排序的时间复杂度

每个桶中的数据数量决定了桶内排序的复杂度。如果所有元素均匀分布到 `k` 个桶中，那么每个桶中的元素大约是 `n/k` 个。通常，我们会在每个桶内使用一种常规的排序算法（如快速排序或插入排序）来对桶内的元素排序。

- 如果使用插入排序或其他 O((n/k)^2) 的排序算法来对每个桶排序，那么对所有桶排序的时间复杂度为 O(k * (n/k)^2) = O(n^2/k)。
- 如果使用更高效的排序算法（如快速排序，时间复杂度为 O((n/k) * log(n/k))），那么对每个桶排序的时间复杂度为 O(n/k * log(n/k))，所有桶的总排序时间复杂度为 O(n * log(n/k))。

#### 3. 合并所有桶中的数据的时间复杂度

在所有桶都排序好之后，需要将它们合并起来，这个步骤的时间复杂度是 O(n)。

 **综合时间复杂度**

综合上述三部分的分析，桶排序的平均时间复杂度为：


**O(n) + O(n \log(n/k)) + O(n) = O(n \log(n/k))**

**桶排序的最坏情况时间复杂度**

桶排序的最坏情况发生在所有元素都被分配到一个桶中，导致排序退化为对所有 `n` 个元素进行一次 O(n log n) 的排序。在这种情况下，桶排序的时间复杂度为：

**O(n \log n)**

总而言之，桶排序在数据分布均匀的情况下效率非常高，但如果数据分布不均匀或者不适合划分到桶中时，可能会退化为更高的复杂度。

### 稳定性

桶排序是否稳定取决于我们将元素插入桶中时是否会改变元素的相对顺序。

## 基数排序

基数排序的发明可以追溯到1887年[赫尔曼·何乐礼](https://zh.wikipedia.org/wiki/赫爾曼·何樂禮)在[打孔卡片制表机](https://zh.wikipedia.org/w/index.php?title=打孔卡片製表機&action=edit&redlink=1)上的贡献[[1\]](https://zh.wikipedia.org/wiki/基数排序#cite_note-1)。基数排序算法早在1923年被广泛运用在[打孔卡](https://zh.wikipedia.org/wiki/打孔卡)的排序。

它是一种典型的非比较型排序算法，所含的算法思想同计数排序有所相似，同时它也不仅可以被用于整数，

### 算法思想

它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。

它使用桶来对同一位数的不同大小进行分装，首先进行个位数的排序存放，再进行十位数的排序存放，然后是百位数...我们可以通过取出最大值来确定最高位数，从而确定需要进行几轮的排序存放操作。

基数排序的方式可以采用**LSD（Least significant digital）**或**MSD（Most significant digital）**，LSD的排序方式由键值的最右边开始，而MSD则相反，由键值的最左边开始。

### 图解

![recording](D:/PixPin/History/recording.gif)

### 代码分析

（注：本段摘自网络，因为觉得写得很好！）

```c++
#include<iostream>
#include<stdlib.h>
using namespace std;
void Radixsort(int a[], int length)//基数排序
{
	int max = a[0], base = 1;//base与max用来判断进行几趟排序
	for (int i = 1; i < length; i++)
	{
		if (max < a[i]) max = a[i];
	}
	int* t = (int*)malloc(sizeof(int) * length);//用t数组临时储存每一趟排好的结果
	while (max / base > 0)//最大数为n位数就进行n次
	{
		int bucket[10] = { 0 };
		for (int i = 0; i < length; i++)//统计每个桶中的数目
			bucket[a[i] / base % 10]++;
		for (int i = 1; i < length; i++)//将各个桶中的数目相加
			bucket[i] += bucket[i - 1];
		for (int i = length - 1; i >= 0; i--)//将数据依次放入桶中
		{
			t[bucket[a[i] / base % 10] - 1] = a[i];
			bucket[a[i] / base % 10]--;
		}
		for (int i = 0; i < length; i++)//将排好的数据放回a数组中
			a[i] = t[i];
		base = base * 10;
	}
}
```

我们需要分析一下这段代码：

- 第一个for

```c++
for(int i=0;i<length;i++)
		   bucket[a[i]/base%10]++;
```

**这里是算出每个桶内有几个数**，bucket[i]代表i号桶内有bucket[i]个数。

- 第二个for

```c++
for(int i=1;i<10;i++)
		   bucket[i]+=bucket[i-1];
```

- 第三个for

```c++
for(int i=length-1;i>=0;i--)
		   {t[bucket[a[i]/base%10]-1]=a[i];
		   bucket[a[i]/base%10]--;} 
```

bucket[a[i]/base%10]就是看a[i]在哪个桶内；-1是观察到在x号桶内的数据要存入t数组的话在t数组的下标是bucket[x]-1；

另一个要注意的是这里是从最后一个数开始存，是因为同一个桶里如果有两个数字 ，那么下面的一个数字在原序列中一定排在上面那个数字的后面，不能够重合。收集的时候如果从前往后收集，就是先收集上面的数字，存放的位置下标不好计算，并不知道桶里有几个数字。

 **MSD 基数排序**

基于 k - 关键字元素的比较方法，可以想到：先比较所有元素的第1关键字，就可以确定出各元素大致的大小关系；然后对 **具有相同第1关键字的元素**，再比较它们的第2关键字……以此类推。

由于是从第1关键字到第k关键字顺序进行比较，由上述思想导出的排序算法称为 MSD（Most Significant Digit first)基数排序。

 **LSD 基数排序**

MSD 基数排序从第1关键字到第k关键字顺序进行比较，为此需要借助递归或迭代来实现，时间常数还是较大，而且在比较自然数上还是略显不便。

而将递归的操作反过来：从第k关键字到第1关键字顺序进行比较，就可以得到 LSD（Least Significant Digit first)基数排序，不使用递归就可以完成的排序算法。

### 时间复杂度

基数排序的时间复杂度可以看成是：**O(k*n)**，n是排序元素的个数，k是位数。这个复杂度往往是优于O(nlogn)的；k的大小决定了要进行的轮数，n是每轮要处理的个数。

基数排序是否比基于比较的排序算法（如快速排序）更好呢？通常情况要比快速排序的期望运行时间代价更好一些。但是，在处理的n个关键字时，**尽管基数排序执行的循环轮数会比快速排序要少，但每一轮它所耗费的时间要长得多**。哪一个排序算法更合适依赖于**具体实现和底层硬件的特性**（例如，快速排序通常可以比基数排序更有效地使用硬件的缓存），以及输人数据的特征。此外，利用计数排序作为中间稳定排序的基数排序不是**原址排序**，而很多O（nlogn）时间的比较排序是**原址排序**。因此，当主存的容量比较宝贵时，我们可能会更倾向于像快速排序这样的原址排序算法。

### 稳定性

如果对内层关键字的排序是稳定的，则 MSD 基数排序和 LSD 基数排序都是**稳定的**排序算法。



![image-20240817175023318](C:/Users/Skrrapper/AppData/Roaming/Typora/typora-user-images/image-20240817175023318.png)



## 外排序

外排序是一种处理极大量以及海量数据的排序方法，适用于数据量大到**无法完全加载到内存**的情况。外排序通常采用”排序-归并“的策略，在面对海量数据的时候，会将数据分块处理并存储在外部存储的介质例如磁盘上，然后依次将这些数据读入内存并进行排序。

实际上外排序可以看成：将内存作为排序的过渡区间，读入内存主要进行分块数据的排序操作，其他时候数据是放在外部存储介质中进行保存的。

### 外归并排序

外归并排序是外排序的典型例子，它使用归并排序的思想，执行先排序再归并的操作，从而进行所有数据的排序。这里我们假设总共1GB的数据需要进行排序，而内存只有100MB，它按照如下方法操作：

1. 读入100MB数据进入内存中，将其进行排序（常规排序即可）
2. 将排序完成的数据重新写入磁盘
3. 进行1与2的过程直到1GB的数据都分次排序完成
4. 按照归并排序来进行所有数据的合成与排序（这里通常使用多路归并算法，K路归并利用优先队列或者堆来选择当前最小的元素，依次输出到最终的结果文件中）

外排序不仅仅只有外归并排序这一种算法，但这里只对其进行简单介绍，如果以后有时间将会介绍其他几种算法。另外还有外分配排序，其原理类似于内排序中的[桶排序](https://zh.wikipedia.org/wiki/桶排序)。在归并排序和桶排序之间存在数学上的某种[对偶](https://zh.wikipedia.org/wiki/对偶)性。此外还有一些不耗费附加磁盘空间的原地排序算法。

### 外排序的特点

- **I/O密集型**：由于涉及大量的读写操作，外排序的性能很大程度上取决于磁盘I/O的效率。

- **适用于大数据集**：外排序能够处理超大规模的数据集，这些数据集远超出内存的容量限制。

### 优化性能

- 并行计算
  - 用多个磁盘驱动器并行处理数据，可以加速顺序磁盘读写。[[4\]](https://zh.wikipedia.org/wiki/外排序#cite_note-4)
  - 在计算机上使用多[线程](https://zh.wikipedia.org/wiki/线程)，可在多核心的计算机上得到优化。
  - 使用[异步输入输出](https://zh.wikipedia.org/w/index.php?title=异步输入输出&action=edit&redlink=1)，可以同时排序和归并，同时读写。
  - 使用多台计算机用高速网络连接，分担计算任务。[[5\]](https://zh.wikipedia.org/wiki/外排序#cite_note-5)
- 提高硬件速度
  - 增大内存，减小磁盘读写次数，减小归并次数。
  - 使用快速的外存设备，比如15000 RPM的硬盘或[固态硬盘](https://zh.wikipedia.org/wiki/固态硬盘)。
  - 使用性能更优良个各种设备，比如使用多核心[CPU](https://zh.wikipedia.org/wiki/CPU)和延迟时间更短的内存。
- 提高软件速度
  - 对于某些特殊数据，在第一阶段的排序中使用[基数排序](https://zh.wikipedia.org/wiki/基数排序)。
  - 压缩输入输出文件和临时文件。

