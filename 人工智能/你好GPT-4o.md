# 你好GPT-4o

## 前言

![image-20240607184619167](C:\Users\Skrrapper\AppData\Roaming\Typora\typora-user-images\image-20240607184619167.png)

2024年5月13日，OpenAI官网发布了他们的新一代自然语言处理交互系统——GPT-4o。这是OpenAI继GPT4之后又一个新的旗舰模型。

**GPT-4o（“o”代表“omni”）**是迈向更自然的**人机交互**的一步——它接受文本、音频、图像和视频的任意组合作为输入，并生成文本、音频和图像输出的任意组合。它可以在短短 232 毫秒内响应音频输入，平均为 320 毫秒，这类似于[人工响应时间（在新窗口中打开）](https://www.pnas.org/doi/10.1073/pnas.0903616106)在对话中。它在英语文本和代码上的能力同 **GPT-4 Turbo** 性能相匹配，在非英语语言的文本上也有显着改进，同时在 API 中也更快且便宜 50%。与现有模型相比，GPT-4o 在视觉和音频理解方面尤其出色。

不能否认的一点是，它与GPT-4的差距并没有像GPT-3.5和GPT-4那样之大，你可以将它看成GPT-4的Ultra版本或者是Pro版本。但基于GPT-4强大的语言处理能力和内容输出的高质量，并在此基础上进行了一次再进化，它变得更快、更强、甚至是**免费面向用户**的——我认为这是它最大的特点之一。

![image-20240607185622362](C:\Users\Skrrapper\AppData\Roaming\Typora\typora-user-images\image-20240607185622362.png)

免费带来的结果：这使更多用户能够更好地体验GPT的功能，并且是使用最新的旗舰版；可能会造成对人工智能的过度的依赖——我们并不知道这是好是坏；带动其他AI公司的内卷上升——这有利于用户，也有利于市场竞争——这是一个好的现象，这说明人工智能服务正在朝着大众的方向前进，也使其变得更加平常化和低成本化，从而能推动诸多事物的发展。

那么这次的人工智能的更新，从技术层面，又为我们带来怎样的惊喜呢？

## 技术层面的Update

### 1.音频、视觉和文本

我们阅读官方的文档可以发现，这次的GPT-4o版本反复强调其在**音频、视觉和文本**上的重要提升。而在我们使用之后也不得不承认这是事实。

[OpenAI GPT-4o guessing May 13th’s announcement on Vimeo](https://vimeo.com/945586717)
上述这段视频是来自OpenAI官网，展示了GPT-4o在视觉和音频理解方面出色的能力。

![img](E:\note\b42b1fcbdf529a312506728c5e064af3455706260.png@1256w_976h_!web-article-pic.avif)

![img](E:\note\aa8f9f337062e434606630b60f84c3cf455706260.png@1256w_1002h_!web-article-pic.avif)

而这主要体现在以下几个点：

- **更深层次的理解**：GPT-4o在处理复杂句子结构和抽象概念方面表现得更加出色，能够更准确地理解上下文并生成连贯的回应。
- **更丰富的词汇量**：它具有更广泛的词汇库，能够更好地处理多种语言和不同领域的专业术语。
- **更丝滑的回答和应对能力**：针对提问者发出的问题，它能够更加人性化地给出答案，并且在给出答案地基础上展现更多符合语境和对话方的语气词以及态度。

同时，有以下几个有趣的点：我们随时说话随时打断GPT，并且它能够理解我们的语气和态度；响应速度极快，无需等待尴尬的2—3秒；可以模仿不同风格的语气——dramatic、robotic、terrible；可以识别符号——人类创作的具有象征意义的符号…诸如此类，还有很多我们意想不到的特征值得我们去探索。

### 2. 知识库扩展
- **更新的知识基础**：GPT-4o基于更新的数据进行训练，因此能够提供更为最新的知识和信息。相较于前代具有更广阔的知识库和更新的数据。
- **更强的推理能力**：在回答需要逻辑推理和复杂推断的问题时表现更好，能够给出更合理和有依据的答案。

### 3. 多模态处理能力的进一步加强

这个特点是基于音视频、文本处理综合而成的。它能够带来综合性的能力展现，给用户更好的融合性能体验。

- **图像理解**：GPT-4o处理和生成与图像相关的文本，进行图像描述、分析和生成相应的文字解释的能力进一步加强，更加准确。
- **跨模态融合**：具备在文本与其他形式数据（如图像、声音等）之间进行更有效的融合和转换的能力。

### 4. 对话管理和互动
- **上下文保持**：GPT-4在长对话中保持上下文一致性的能力更强，能够更好地理解和记住之前的对话内容。
- **情感和语气控制**：能够根据用户的情感和对话语境调整回应的语气，更加自然和人性化。

### 5. 编程与技术问答
- **代码生成和理解**：在编程帮助和技术问题解答方面，GPT-4o表现得更为出色，能够生成更高质量的代码并解释复杂的技术概念。
- **多语言支持**：支持更多的编程语言，并能够处理复杂的编程任务和跨语言的技术问题。
- **用户体验上升**：用户在编写代码的过程中对于GPT的使用更加顺滑和便捷。

### 6. 创造性任务
- **创意写作**：在写作小说、剧本、诗歌等创造性任务方面，GPT-4o展现了更强的创造力和连贯性。
- **内容生成**：能够生成更有创意和原创性的内容，满足用户多样化的内容需求。

### 7. 用户体验
- **响应速度**：处理和生成文本的速度更快，提升了用户的整体体验。
- **提供了更好的UI**：通过更直观和用户友好的界面，增强用户的互动体验。
- **API的开放**

### 8.人工智能之间的互相对话

这次官网的展示视频中，有一个视频很有趣，那就是两个GPT-4o之间的对话。

![image-20240607191744331](C:\Users\Skrrapper\AppData\Roaming\Typora\typora-user-images\image-20240607191744331.png)

第一个点：互动

第二个点：唱歌

这倒也是实现了机机交互。

## **GPT-4 Turbo 与 GPT-4o**

GPT-4o 具有相同的高智商，但比 GPT-4 Turbo 更快、更便宜，并且具有更高的速率限制。具体说来：

- 定价：GPT-4o 比 GPT-4 Turbo 便宜 50%，输入 5 美元/月，输出代币 15 美元/M）。
- 速率限制：GPT-4o 的速率限制是 GPT-4 Turbo 的 5 倍——每分钟最多 1000 万个代币。
- 速度：GPT-4o 的速度是 GPT-2 Turbo 的 4 倍。
- 视觉：GPT-4o 的视觉能力在与视觉能力相关的评估中表现优于 GPT-4 Turbo。
- 多语言：GPT-4o 改进了对非英语语言的支持，而不是 GPT-4 Turbo。

GPT-4o 目前的上下文窗口为 128k，知识截止日期为 2023 年 10 月。

## 思考与找出其不足

![image-20240609101053599](E:\note\image-20240609101053599.png)

当我们聊完了它的优点之后，特别是对比它的前辈GPT-4之后，我们不得不想去找出它的缺点、或者是不足来证明它为啥免费提供、为啥在套餐中的限用额度还是比GPT-4高——也就是说相较于4它更便宜。

首先从**模型的名字上**来看，GPT-4和4o仅仅只差了一个字母**o**，而3和4却是直接差了**一代**。为什么不将其直接命名为5呢？可以猜测，OpenAI这次发布的新产品，实际上也是在为他们的下一代旗舰模型——**GPT-5**做准备，这次的4o只是预热，就如当年GPT-3.5的免费紧随着GPT-4的发布。很有可能在接下来的一年（保守）之内，OpenAI将会释放出他们的全新模型，并且是一次新的提升，在某个我们难以预料又或许常用的方面具有巨大的提升，所以我们拭目以待。

![image-20240609114417598](E:\note\image-20240609114417598.png)

另外，其实相较于GPT-4o，4的训练模型已经足够成熟，并且能够胜任大部分工作，**所以它依旧是作为工作辅助的首选**。从人们的接受度来看也会选择更加老练的版本，这样更为靠谱，那么公司为了盈利，当然就会将他们更熟练的模型定价更高，从而获得更多利润，这是从公司盈利的角度。

那么从这次的更新上来看，确实也有些不足的地方：

**例如在与其对话的过程中，打断说话时的处理方式较为生硬**，我们可能还是需要按下暂停键才能打断GPT，我认为真正的语言交互或许是无差别对话：也就是不需要任何按键或者提示，你可以随时开启对话，随时打断对话，随时结束对话，甚至加上情境，何时结束对话较为合适，我们应该说些什么让气氛不那么尴尬等等。

奥特曼回应称，OpenAI会继续改进并提升语音功能的质量：“我相信，语音交互是通向未来交互方式的一个重要线索。如果能够实现真正优质的语音互动体验，将会是一种与计算机互动的全新方式。”“我相信，语音交互是通向未来交互方式的一个重要线索。如果能够实现真正优质的语音互动体验，将会是一种与计算机互动的全新方式。”

另外其他例如语音生成的速度依旧不够快、语气处理有待加强、在较为复杂的问题上还是会有疏漏等等，实际上这些也算是老问题了——但这也算挑刺，毕竟这次的更新还是有着极大的飞跃的。

## 你好GPT，未来会怎样？

![image-20240609115126083](E:\note\image-20240609115126083.png)

当我不带任何提示词问GPT时，给出的答案是有条有理——条条框框的。
而当我使用**语音对话（基于3.5的模型）**问它这个问题时，我发现与这次发布的4o确实有较大差距。无论是从回答上还是从语音的处理上。

或许人工智能的发展总是充满奇迹和想象力，而当我们沉溺于技术的发展时，总不能忘记我们时刻要保持清醒，理性看待——尽管这是这两年来老生常谈的问题，但我们依旧不可忽视。

未来会是如何？无人知晓，让我们期待GPT-5、6、7的到来，并且对此再去享受、去适应、去思考。
